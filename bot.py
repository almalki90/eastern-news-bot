#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ø¨ÙˆØª ØªÙ„ÙŠØ¬Ø±Ø§Ù… Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø´Ø±Ù‚ÙŠØ© - Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©
ÙŠØ¬Ù„Ø¨ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ù…Ù† RSS feeds ÙˆÙŠØ±Ø³Ù„Ù‡Ø§ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ù„Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª
"""

import feedparser
import requests
import json
import os
import time
import re
from datetime import datetime
from typing import List, Dict

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¨ÙˆØª
BOT_TOKEN = os.environ.get('BOT_TOKEN', '8281406621:AAGpJOnC1Ua1I4t49h8kWea-7pND8zTSBhg')
TELEGRAM_API = f'https://api.telegram.org/bot{BOT_TOKEN}'

# Ù…ØµØ§Ø¯Ø± RSS Ù„Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ© Ø§Ù„Ù…Ø­Ù„ÙŠØ©
RSS_FEEDS = [
    # Google News - Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø´Ø±Ù‚ÙŠØ© (Ø¨Ø­Ø« Ù…Ø®ØµØµ)
    {
        'name': 'Google News - Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø´Ø±Ù‚ÙŠØ©',
        'url': 'https://news.google.com/rss/search?q=Ø§Ù„Ù…Ù†Ø·Ù‚Ø©+Ø§Ù„Ø´Ø±Ù‚ÙŠØ©+OR+Ø§Ù„Ø¯Ù…Ø§Ù…+OR+Ø§Ù„Ø®Ø¨Ø±+OR+Ø§Ù„Ø¸Ù‡Ø±Ø§Ù†+when:7d&hl=ar&gl=SA&ceid=SA:ar',
        'enabled': True
    },
    {
        'name': 'Google News - Ø§Ù„Ø¯Ù…Ø§Ù… Ø§Ù„Ø®Ø¨Ø±',
        'url': 'https://news.google.com/rss/search?q=Ø§Ù„Ø¯Ù…Ø§Ù…+OR+Ø§Ù„Ø®Ø¨Ø±+OR+Ø§Ù„Ù‚Ø·ÙŠÙ+when:7d&hl=ar&gl=SA&ceid=SA:ar',
        'enabled': True
    },
    {
        'name': 'Google News - Ø§Ù„Ø£Ø­Ø³Ø§Ø¡ Ø§Ù„Ø¬Ø¨ÙŠÙ„',
        'url': 'https://news.google.com/rss/search?q=Ø§Ù„Ø£Ø­Ø³Ø§Ø¡+OR+Ø§Ù„Ø¬Ø¨ÙŠÙ„+OR+Ø­ÙØ±+Ø§Ù„Ø¨Ø§Ø·Ù†+when:7d&hl=ar&gl=SA&ceid=SA:ar',
        'enabled': True
    },
    # Ù…ØµØ§Ø¯Ø± Ø¹Ø±Ø¨ÙŠØ© Ø¹Ø§Ù…Ø© (Ù„Ù„ÙÙ„ØªØ±Ø©)
    {
        'name': 'Ø¹Ø±Ø¨ Ù†ÙŠÙˆØ² - Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©',
        'url': 'https://www.arabnews.com/rss/saudi-arabia',
        'enabled': True
    },
    {
        'name': 'Ø§Ù„Ø´Ø±Ù‚ Ø§Ù„Ø£ÙˆØ³Ø·',
        'url': 'https://aawsat.com/feed',
        'enabled': True
    }
]

# Ù…Ù„Ù Ù„Ø­ÙØ¸ Ø¢Ø®Ø± Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù…Ø±Ø³Ù„Ø©
SENT_NEWS_FILE = 'sent_news.json'

# ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© Ù„Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø´Ø±Ù‚ÙŠØ© - ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ­ØªÙˆÙŠ Ø§Ù„Ø®Ø¨Ø± Ø¹Ù„Ù‰ ÙˆØ§Ø­Ø¯Ø© Ù…Ù†Ù‡Ø§ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„
EASTERN_PROVINCE_KEYWORDS = [
    # Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø´Ø±Ù‚ÙŠØ©
    'Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø´Ø±Ù‚ÙŠØ©', 'Ø§Ù„Ø´Ø±Ù‚ÙŠØ©',
    # Ø§Ù„Ù…Ø¯Ù† Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
    'Ø§Ù„Ø¯Ù…Ø§Ù…', 'dammam',
    'Ø§Ù„Ø®Ø¨Ø±', 'khobar', 'al khobar',
    'Ø§Ù„Ø¸Ù‡Ø±Ø§Ù†', 'dhahran',
    'Ø§Ù„Ø¬Ø¨ÙŠÙ„', 'jubail',
    'Ø§Ù„Ø£Ø­Ø³Ø§Ø¡', 'Ø§Ù„Ø§Ø­Ø³Ø§Ø¡', 'al-ahsa', 'al ahsa', 'ahsa',
    'Ø§Ù„Ù‡ÙÙˆÙ', 'hofuf',
    'Ø­ÙØ± Ø§Ù„Ø¨Ø§Ø·Ù†', 'hafr al-batin', 'hafar albatin',
    'Ø§Ù„Ù‚Ø·ÙŠÙ', 'qatif',
    'Ø§Ù„Ù†Ø¹ÙŠØ±ÙŠØ©', 'nairiyah',
    'Ø±Ø£Ø³ Ø§Ù„Ø®ÙŠØ±', 'ras al khair',
    'Ø§Ù„Ø®ÙØ¬ÙŠ', 'khafji',
    # Ù…Ø¹Ø§Ù„Ù… Ù…Ø´Ù‡ÙˆØ±Ø©
    'ÙƒÙˆØ±Ù†ÙŠØ´ Ø§Ù„Ø¯Ù…Ø§Ù…', 'ÙƒÙˆØ±Ù†ÙŠØ´ Ø§Ù„Ø®Ø¨Ø±',
    'Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ø¯Ù…Ø§Ù…', 'Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ù…Ù„Ùƒ ÙÙ‡Ø¯ Ù„Ù„Ø¨ØªØ±ÙˆÙ„',
    'Ø£Ø±Ø§Ù…ÙƒÙˆ', 'aramco',
    'Ø§Ù„Ù…Ù„Ùƒ ÙÙ‡Ø¯', 'king fahd',
    # Ø£Ø­ÙŠØ§Ø¡ ÙˆÙ…Ù†Ø§Ø·Ù‚
    'Ø§Ù„Ø±Ø§ÙƒØ©', 'Ø§Ù„Ø¹Ø²ÙŠØ²ÙŠØ©', 'Ø§Ù„ÙÙŠØµÙ„ÙŠØ©', 'Ø§Ù„Ø´Ø§Ø·Ø¦'
]


def load_sent_news() -> Dict:
    """ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù…Ø±Ø³Ù„Ø© Ø³Ø§Ø¨Ù‚Ø§Ù‹"""
    if os.path.exists(SENT_NEWS_FILE):
        try:
            with open(SENT_NEWS_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            return {}
    return {}


def save_sent_news(sent_news: Dict):
    """Ø­ÙØ¸ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù…Ø±Ø³Ù„Ø©"""
    with open(SENT_NEWS_FILE, 'w', encoding='utf-8') as f:
        json.dump(sent_news, f, ensure_ascii=False, indent=2)


def get_bot_chats() -> List[int]:
    """
    Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª/Ø§Ù„Ù‚Ù†ÙˆØ§Øª Ø§Ù„ØªÙŠ Ø§Ù„Ø¨ÙˆØª ÙÙŠÙ‡Ø§ ÙƒÙ…Ø´Ø±Ù
    """
    try:
        # Ø¬Ù„Ø¨ Ø§Ù„ØªØ­Ø¯ÙŠØ«Ø§Øª Ø§Ù„Ø£Ø®ÙŠØ±Ø©
        response = requests.get(f'{TELEGRAM_API}/getUpdates', timeout=10)
        updates = response.json()
        
        chat_ids = set()
        if updates.get('ok'):
            for update in updates.get('result', []):
                # Ø¬Ù„Ø¨ chat_id Ù…Ù† Ø§Ù„Ø±Ø³Ø§Ø¦Ù„
                if 'message' in update:
                    chat_id = update['message']['chat']['id']
                    chat_type = update['message']['chat']['type']
                    # ÙÙ‚Ø· Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª ÙˆØ§Ù„Ù‚Ù†ÙˆØ§Øª (Ù„ÙŠØ³ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ø®Ø§ØµØ©)
                    if chat_type in ['group', 'supergroup', 'channel']:
                        chat_ids.add(chat_id)
                        
        return list(chat_ids)
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª: {e}")
        return []


def is_protocol_news(news_item: Dict) -> bool:
    """
    Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„Ø®Ø¨Ø± Ø¨Ø±ÙˆØªÙˆÙƒÙˆÙ„ÙŠ (Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ØŒ Ø²ÙŠØ§Ø±Ø§ØªØŒ ØªÙ‡Ù†Ø¦Ø©...)
    Ù†Ø±ÙŠØ¯ Ø§Ø³ØªØ¨Ø¹Ø§Ø¯ Ù‡Ø°Ù‡ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±
    """
    title = news_item.get('title', '').lower()
    summary = news_item.get('summary', '').lower()
    full_text = f"{title} {summary}"
    
    # ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© Ù„Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø¨Ø±ÙˆØªÙˆÙƒÙˆÙ„ÙŠØ©
    protocol_keywords = [
        'Ø§Ø³ØªÙ‚Ø¨Ù„', 'ÙŠØ³ØªÙ‚Ø¨Ù„', 'Ø§Ø³ØªÙ‚Ø¨Ø§Ù„', 'ÙˆØ¯Ø¹', 'ÙŠÙˆØ¯Ø¹', 'ÙˆØ¯Ø§Ø¹',
        'Ø±Ø¹Ù‰', 'ÙŠØ±Ø¹Ù‰', 'Ø±Ø¹Ø§ÙŠØ©', 'Ø§ÙØªØªØ­ Ø­ÙÙ„', 'Ø­Ø¶Ø± Ø­ÙÙ„',
        'ÙƒØ±Ù…', 'ÙŠÙƒØ±Ù…', 'ØªÙƒØ±ÙŠÙ…', 'Ù‡Ù†Ø£', 'ÙŠÙ‡Ù†Ø¦', 'ØªÙ‡Ù†Ø¦Ø©',
        'Ø§Ù„ØªÙ‚Ù‰', 'ÙŠÙ„ØªÙ‚ÙŠ', 'Ù„Ù‚Ø§Ø¡', 'Ø²Ø§Ø±', 'ÙŠØ²ÙˆØ±', 'Ø²ÙŠØ§Ø±Ø©',
        'Ø§Ø·Ù„Ø¹ Ø¹Ù„Ù‰', 'ÙŠØ·Ù„Ø¹ Ø¹Ù„Ù‰', 'ØªÙÙ‚Ø¯', 'ÙŠØªÙÙ‚Ø¯'
    ]
    
    # Ø¥Ø°Ø§ ÙˆÙØ¬Ø¯Øª Ø£ÙŠ ÙƒÙ„Ù…Ø© Ø¨Ø±ÙˆØªÙˆÙƒÙˆÙ„ÙŠØ©
    for keyword in protocol_keywords:
        if keyword in full_text:
            return True
    
    return False


def is_valuable_news(news_item: Dict) -> bool:
    """
    Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„Ø®Ø¨Ø± Ù‚ÙŠÙ‘Ù… (ÙˆØ¸Ø§Ø¦ÙØŒ Ù…Ø´Ø§Ø±ÙŠØ¹ØŒ ØªØ±Ø³ÙŠØ§ØªØŒ Ù…Ù†Ø§Ù‚ØµØ§Øª...)
    """
    title = news_item.get('title', '').lower()
    summary = news_item.get('summary', '').lower()
    full_text = f"{title} {summary}"
    
    # ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© Ù„Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù…Ù‡Ù…Ø©
    valuable_keywords = [
        # ÙˆØ¸Ø§Ø¦Ù
        'ÙˆØ¸ÙŠÙØ©', 'ÙˆØ¸Ø§Ø¦Ù', 'ØªÙˆØ¸ÙŠÙ', 'ØªØ¹ÙŠÙŠÙ†', 'ØªØ¹ÙŠÙŠÙ†Ø§Øª', 'ÙØ±Øµ Ø¹Ù…Ù„',
        'Ù…Ø³Ø§Ø¨Ù‚Ø© ÙˆØ¸ÙŠÙÙŠØ©', 'Ø¥Ø¹Ù„Ø§Ù† ÙˆØ¸ÙŠÙÙŠ', 'Ø±ÙˆØ§ØªØ¨',
        # Ù…Ø´Ø§Ø±ÙŠØ¹
        'Ù…Ø´Ø±ÙˆØ¹', 'Ù…Ø´Ø§Ø±ÙŠØ¹', 'ØªÙ†ÙÙŠØ° Ù…Ø´Ø±ÙˆØ¹', 'Ø¥Ø·Ù„Ø§Ù‚ Ù…Ø´Ø±ÙˆØ¹', 'Ù…Ø´Ø±ÙˆØ¹ ØªØ·ÙˆÙŠØ±',
        'Ø¨Ù†Ø§Ø¡', 'Ø¥Ù†Ø´Ø§Ø¡', 'ØªØ´ÙŠÙŠØ¯', 'ØªØ·ÙˆÙŠØ±', 'ØªÙˆØ³Ø¹Ø©',
        # ØªØ±Ø³ÙŠØ§Øª ÙˆÙ…Ù†Ø§Ù‚ØµØ§Øª
        'ØªØ±Ø³ÙŠØ©', 'ØªØ±Ø³ÙŠØ§Øª', 'Ù…Ù†Ø§Ù‚ØµØ©', 'Ù…Ù†Ø§Ù‚ØµØ§Øª', 'Ø¹Ù‚Ø¯', 'Ø¹Ù‚ÙˆØ¯',
        'Ù…Ø´ØªØ±ÙŠØ§Øª', 'Ø·Ø±Ø­', 'Ù…Ø²Ø§ÙŠØ¯Ø©', 'Ù…Ù†Ø§ÙØ³Ø©',
        # Ø§Ø³ØªØ«Ù…Ø§Ø± ÙˆØ§Ù‚ØªØµØ§Ø¯
        'Ø§Ø³ØªØ«Ù…Ø§Ø±', 'Ø§Ø³ØªØ«Ù…Ø§Ø±Ø§Øª', 'Ù…Ù„ÙŠØ§Ø±', 'Ù…Ù„ÙŠÙˆÙ†', 'Ø±ÙŠØ§Ù„',
        'Ø§Ù‚ØªØµØ§Ø¯', 'Ø§Ù‚ØªØµØ§Ø¯ÙŠ', 'ØªØ¬Ø§Ø±ÙŠ', 'ØµÙ†Ø§Ø¹ÙŠ',
        # Ø®Ø¯Ù…Ø§Øª Ø¹Ø§Ù…Ø©
        'Ø®Ø¯Ù…Ø©', 'Ø®Ø¯Ù…Ø§Øª', 'ØªØ´ØºÙŠÙ„', 'ØµÙŠØ§Ù†Ø©', 'Ù†Ø¸Ø§ÙØ©', 'Ø£Ù…Ù†',
        'Ù†Ù‚Ù„', 'Ø·Ø±Ù‚', 'Ø¬Ø³Ø±', 'ÙƒÙ‡Ø±Ø¨Ø§Ø¡', 'Ù…ÙŠØ§Ù‡', 'ØµØ±Ù ØµØ­ÙŠ',
        # ØªØ¹Ù„ÙŠÙ… ÙˆØµØ­Ø©
        'Ù…Ø¯Ø±Ø³Ø©', 'Ù…Ø³ØªØ´ÙÙ‰', 'Ù…Ø±ÙƒØ² ØµØ­ÙŠ', 'Ø¬Ø§Ù…Ø¹Ø©', 'Ù…Ø¹Ù‡Ø¯',
        'ØªØ¹Ù„ÙŠÙ…', 'ØµØ­Ø©', 'Ø·Ø¨ÙŠ', 'Ø¯Ø±Ø§Ø³ÙŠ',
        # Ø¹Ù‚Ø§Ø±Ø§Øª
        'Ø£Ø±Ø§Ø¶ÙŠ', 'Ø¹Ù‚Ø§Ø±', 'Ø¹Ù‚Ø§Ø±ÙŠ', 'Ø³ÙƒÙ†ÙŠ', 'Ø¥Ø³ÙƒØ§Ù†'
    ]
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£ÙŠ ÙƒÙ„Ù…Ø© Ù…ÙØªØ§Ø­ÙŠØ© Ù‚ÙŠÙ‘Ù…Ø©
    for keyword in valuable_keywords:
        if keyword in full_text:
            return True
    
    return False


def is_eastern_province_news(news_item: Dict) -> bool:
    """
    Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„Ø®Ø¨Ø± ÙŠØªØ¹Ù„Ù‚ Ø¨Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø´Ø±Ù‚ÙŠØ©
    ÙŠØ¨Ø­Ø« Ø¹Ù† Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© ÙÙŠ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† ÙˆØ§Ù„Ù…Ù„Ø®Øµ
    """
    title = news_item.get('title', '').lower()
    summary = news_item.get('summary', '').lower()
    
    # Ø¯Ù…Ø¬ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† ÙˆØ§Ù„Ù…Ù„Ø®Øµ Ù„Ù„Ø¨Ø­Ø«
    full_text = f"{title} {summary}"
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£ÙŠ ÙƒÙ„Ù…Ø© Ù…ÙØªØ§Ø­ÙŠØ©
    for keyword in EASTERN_PROVINCE_KEYWORDS:
        if keyword.lower() in full_text:
            return True
    
    return False


def fetch_rss_news(feed_url: str, feed_name: str, max_items: int = 20) -> List[Dict]:
    """Ø¬Ù„Ø¨ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ù…Ù† RSS feed"""
    try:
        print(f"ğŸ“¡ Ø¬Ù„Ø¨ Ø£Ø®Ø¨Ø§Ø± Ù…Ù†: {feed_name}")
        feed = feedparser.parse(feed_url)
        
        news_items = []
        for entry in feed.entries[:max_items]:
            news_item = {
                'title': entry.get('title', 'Ø¨Ø¯ÙˆÙ† Ø¹Ù†ÙˆØ§Ù†'),
                'link': entry.get('link', ''),
                'summary': entry.get('summary', entry.get('description', '')),
                'published': entry.get('published', ''),
                'source': feed_name,
                'id': entry.get('id', entry.get('link', ''))
            }
            news_items.append(news_item)
        
        print(f"âœ… ØªÙ… Ø¬Ù„Ø¨ {len(news_items)} Ø®Ø¨Ø± Ù…Ù† {feed_name}")
        return news_items
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ {feed_name}: {e}")
        return []


def clean_text(text: str) -> str:
    """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ Ù…Ù† HTML ÙˆØ§Ù„Ø£Ø­Ø±Ù Ø§Ù„Ø²Ø§Ø¦Ø¯Ø©"""
    if not text:
        return ""
    
    # Ø¥Ø²Ø§Ù„Ø© HTML tags
    text = re.sub(r'<[^>]+>', '', text)
    
    # Ø¥Ø²Ø§Ù„Ø© Ù…Ø³Ø§ÙØ§Øª Ø²Ø§Ø¦Ø¯Ø© ÙˆÙ…Ø­Ø§Ø±Ù Ø®Ø§ØµØ©
    text = re.sub(r'\s+', ' ', text)
    text = text.strip()
    
    return text


def shorten_url(url: str) -> str:
    """Ø§Ø®ØªØµØ§Ø± Ø§Ù„Ø±Ø§Ø¨Ø· Ù„Ø¹Ø±Ø¶ Ø£ÙØ¶Ù„"""
    try:
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø³Ù… Ø§Ù„Ù…ÙˆÙ‚Ø¹ ÙÙ‚Ø·
        from urllib.parse import urlparse
        parsed = urlparse(url)
        domain = parsed.netloc.replace('www.', '')
        return domain
    except:
        return url[:30] + '...'


def are_similar_news(title1: str, title2: str) -> bool:
    """
    Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ù„Ù…Ù†Ø¹ Ø§Ù„ØªÙƒØ±Ø§Ø±
    ÙŠÙ‚Ø§Ø±Ù† Ø£ÙˆÙ„ 50 Ø­Ø±Ù Ù…Ù† Ø§Ù„Ø¹Ù†ÙˆØ§Ù†ÙŠÙ†
    """
    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ†
    t1 = clean_text(title1).lower()[:50]
    t2 = clean_text(title2).lower()[:50]
    
    # Ø­Ø³Ø§Ø¨ Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡
    if len(t1) < 10 or len(t2) < 10:
        return False
    
    # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø£Ø­Ø¯Ù‡Ù…Ø§ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø¢Ø®Ø±
    if t1 in t2 or t2 in t1:
        return True
    
    # Ø­Ø³Ø§Ø¨ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ø´ØªØ±ÙƒØ©
    words1 = set(t1.split())
    words2 = set(t2.split())
    common = words1.intersection(words2)
    
    # Ø¥Ø°Ø§ ÙƒØ§Ù† 70% Ù…Ù† Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ù…Ø´ØªØ±ÙƒØ©
    similarity = len(common) / max(len(words1), len(words2))
    return similarity > 0.7


def format_news_message(news_item: Dict) -> str:
    """ØªÙ†Ø³ÙŠÙ‚ Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø®Ø¨Ø± - Ù†Ø¨Ø°Ø© Ù‚ØµÙŠØ±Ø© Ù…Ø¹ Ø§Ù„Ù…ØµØ¯Ø±"""
    title = clean_text(news_item['title'])
    link = news_item['link']
    source = news_item['source']
    summary = clean_text(news_item.get('summary', ''))
    
    # ØªÙ‚Ù„ÙŠØµ Ø§Ù„Ù…Ù„Ø®Øµ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø·ÙˆÙŠÙ„Ø§Ù‹
    if summary and len(summary) > 200:
        summary = summary[:197] + '...'
    
    # Ø±Ø³Ø§Ù„Ø© Ø¨Ø³ÙŠØ·Ø© ÙˆÙˆØ§Ø¶Ø­Ø©
    message = f"ğŸ“° {title}\n\n"
    
    if summary and summary != title:
        message += f"{summary}\n\n"
    
    message += f"ğŸ“Œ {source}"
    
    # Ø¥Ø¶Ø§ÙØ© Ø±Ø§Ø¨Ø· Ù…Ø®ØªØµØ± Ø§Ø®ØªÙŠØ§Ø±ÙŠ (Ù…Ø¹Ù„Ù‚ - ÙŠÙ…ÙƒÙ† ØªÙØ¹ÙŠÙ„Ù‡ Ù„Ø§Ø­Ù‚Ø§Ù‹)
    # short_domain = shorten_url(link)
    # message += f" | ğŸ”— {short_domain}"
    
    return message


def send_telegram_message(chat_id: int, message: str, retry_count: int = 3) -> bool:
    """Ø¥Ø±Ø³Ø§Ù„ Ø±Ø³Ø§Ù„Ø© Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©/Ù‚Ù†Ø§Ø© ÙÙŠ ØªÙ„ÙŠØ¬Ø±Ø§Ù… Ù…Ø¹ retry"""
    for attempt in range(retry_count):
        try:
            payload = {
                'chat_id': chat_id,
                'text': message,
                'disable_web_page_preview': False
            }
            
            response = requests.post(
                f'{TELEGRAM_API}/sendMessage',
                json=payload,
                timeout=10
            )
            
            result = response.json()
            if result.get('ok'):
                return True
            else:
                error_desc = result.get('description', '')
                
                # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø®Ø·Ø£ "Too Many Requests"ØŒ Ø§Ù†ØªØ¸Ø± ÙˆØ£Ø¹Ø¯ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©
                if 'Too Many Requests' in error_desc:
                    retry_after = result.get('parameters', {}).get('retry_after', 5)
                    print(f"â³ ØªÙ„ÙŠØ¬Ø±Ø§Ù… ÙŠØ·Ù„Ø¨ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± {retry_after} Ø«Ø§Ù†ÙŠØ©...")
                    time.sleep(retry_after + 1)
                    continue
                else:
                    print(f"âŒ ÙØ´Ù„ Ø§Ù„Ø¥Ø±Ø³Ø§Ù„ Ù„Ù€ {chat_id}: {error_desc}")
                    return False
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¥Ø±Ø³Ø§Ù„ (Ù…Ø­Ø§ÙˆÙ„Ø© {attempt + 1}): {e}")
            if attempt < retry_count - 1:
                time.sleep(2)
                continue
            return False
    
    return False


def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    print(f"\nğŸ¤– Ø¨Ø¯Ø¡ Ø¨ÙˆØª Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø´Ø±Ù‚ÙŠØ© - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù…Ø±Ø³Ù„Ø© Ø³Ø§Ø¨Ù‚Ø§Ù‹
    sent_news = load_sent_news()
    
    # Ø¬Ù„Ø¨ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª
    chat_ids = get_bot_chats()
    
    # Ø¥Ø¶Ø§ÙØ© chat IDs ÙŠØ¯ÙˆÙŠØ§Ù‹ Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„ÙŠÙ‡Ø§ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
    # ÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ø¶Ø§ÙØ© IDs Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ù‡Ù†Ø§:
    # chat_ids = [-1001234567890, -1009876543210]
    
    if not chat_ids:
        print("âš ï¸  Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø§Øª. ØªØ£ÙƒØ¯ Ù…Ù†:")
        print("   1. Ø§Ù„Ø¨ÙˆØª Ù…Ø¶Ø§Ù Ù„Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª")
        print("   2. Ø§Ù„Ø¨ÙˆØª Ù„Ø¯ÙŠÙ‡ ØµÙ„Ø§Ø­ÙŠØ§Øª Ø§Ù„Ø¥Ø±Ø³Ø§Ù„")
        print("   3. Ù‡Ù†Ø§Ùƒ Ø±Ø³Ø§Ø¦Ù„ Ø³Ø§Ø¨Ù‚Ø© ÙÙŠ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª")
        print("\nğŸ’¡ ÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ø¶Ø§ÙØ© chat IDs ÙŠØ¯ÙˆÙŠØ§Ù‹ ÙÙŠ Ø§Ù„ÙƒÙˆØ¯")
        return
    
    print(f"ğŸ“± ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(chat_ids)} Ù…Ø¬Ù…ÙˆØ¹Ø©/Ù‚Ù†Ø§Ø©")
    
    # Ø¬Ù„Ø¨ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ù…Ù† ÙƒÙ„ Ø§Ù„Ù…ØµØ§Ø¯Ø±
    all_news = []
    for feed in RSS_FEEDS:
        if not feed.get('enabled', True):
            continue
        news_items = fetch_rss_news(feed['url'], feed['name'])
        all_news.extend(news_items)
    
    print(f"\nğŸ“Š Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±: {len(all_news)}")
    
    # ÙÙ„ØªØ±Ø© Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù…ØªØ¹Ù„Ù‚Ø© Ø¨Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø´Ø±Ù‚ÙŠØ© ÙÙ‚Ø·
    eastern_news = []
    for news in all_news:
        if is_eastern_province_news(news):
            eastern_news.append(news)
    
    print(f"ğŸ™ï¸  Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø´Ø±Ù‚ÙŠØ©: {len(eastern_news)}")
    
    # Ø§Ø³ØªØ¨Ø¹Ø§Ø¯ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø¨Ø±ÙˆØªÙˆÙƒÙˆÙ„ÙŠØ© ÙˆØ§Ù„ØªØ±ÙƒÙŠØ² Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù‚ÙŠÙ‘Ù…Ø©
    valuable_news = []
    protocol_count = 0
    for news in eastern_news:
        # Ø§Ø³ØªØ¨Ø¹Ø§Ø¯ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø¨Ø±ÙˆØªÙˆÙƒÙˆÙ„ÙŠØ©
        if is_protocol_news(news):
            protocol_count += 1
            continue
        
        # Ù‚Ø¨ÙˆÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù‚ÙŠÙ‘Ù…Ø© ÙÙ‚Ø·
        if is_valuable_news(news):
            valuable_news.append(news)
    
    print(f"ğŸš« ØªÙ… Ø§Ø³ØªØ¨Ø¹Ø§Ø¯ {protocol_count} Ø®Ø¨Ø± Ø¨Ø±ÙˆØªÙˆÙƒÙˆÙ„ÙŠ")
    print(f"âœ… Ø£Ø®Ø¨Ø§Ø± Ù‚ÙŠÙ‘Ù…Ø© (ÙˆØ¸Ø§Ø¦ÙØŒ Ù…Ø´Ø§Ø±ÙŠØ¹ØŒ ØªØ±Ø³ÙŠØ§Øª...): {len(valuable_news)}")
    
    # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù‚ÙŠÙ‘Ù…Ø© Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† ÙƒÙ„ Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù…Ù†Ø·Ù‚Ø©
    eastern_news = valuable_news
    
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù…ÙƒØ±Ø±Ø©
    unique_news = []
    for news in eastern_news:
        is_duplicate = False
        for existing in unique_news:
            if are_similar_news(news['title'], existing['title']):
                is_duplicate = True
                break
        
        if not is_duplicate:
            unique_news.append(news)
    
    print(f"ğŸ”„ Ø¨Ø¹Ø¯ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±: {len(unique_news)}")
    
    # ÙÙ„ØªØ±Ø© Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© ÙÙ‚Ø·
    new_news = []
    for news in unique_news:
        news_id = news['id']
        if news_id not in sent_news:
            new_news.append(news)
            sent_news[news_id] = {
                'title': news['title'],
                'sent_at': datetime.now().isoformat()
            }
    
    print(f"ğŸ†• Ø£Ø®Ø¨Ø§Ø± Ø¬Ø¯ÙŠØ¯Ø©: {len(new_news)}")
    
    # ØªØ­Ø¯ÙŠØ¯ Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ù„Ù„Ø¥Ø±Ø³Ø§Ù„ (Ø­Ø¯ Ø£Ù‚ØµÙ‰ 8 Ù„ØªØ¬Ù†Ø¨ Ø§Ù„Ø­Ø¸Ø±)
    max_news_to_send = 8
    if len(new_news) > max_news_to_send:
        print(f"âš ï¸  Ø³ÙŠØªÙ… Ø¥Ø±Ø³Ø§Ù„ Ø£ÙˆÙ„ {max_news_to_send} Ø®Ø¨Ø± ÙÙ‚Ø· (Ù…Ù† {len(new_news)})")
        news_to_send = new_news[:max_news_to_send]
    else:
        news_to_send = new_news
    
    # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
    sent_count = 0
    for i, news in enumerate(news_to_send, 1):
        message = format_news_message(news)
        
        for chat_id in chat_ids:
            if send_telegram_message(chat_id, message):
                sent_count += 1
                print(f"âœ… [{i}/{len(news_to_send)}] ØªÙ… Ø¥Ø±Ø³Ø§Ù„: {news['title'][:50]}...")
            else:
                print(f"âŒ [{i}/{len(news_to_send)}] ÙØ´Ù„ Ø¥Ø±Ø³Ø§Ù„: {news['title'][:50]}...")
            
            # Ø§Ù†ØªØ¸Ø§Ø± Ù‚ØµÙŠØ± Ø¨ÙŠÙ† ÙƒÙ„ Ø±Ø³Ø§Ù„Ø© Ù„ØªØ¬Ù†Ø¨ rate limiting
            time.sleep(1)
    
    # Ø­ÙØ¸ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù…Ø±Ø³Ù„Ø©
    save_sent_news(sent_news)
    
    print(f"\nâœ¨ ØªÙ… Ø¥Ø±Ø³Ø§Ù„ {sent_count} Ø±Ø³Ø§Ù„Ø© Ø¨Ù†Ø¬Ø§Ø­!")
    print("=" * 60)


if __name__ == '__main__':
    main()
